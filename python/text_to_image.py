# 1ã€pip install diffusers transformers torch accelerate fastapi uvicorn
# 2ã€uvicorn main:app --host 0.0.0.0 --port 8080
# 3ã€curl http://localhost:8080/v1/images/generations \
#   -H "Content-Type: application/json" \
#   -d '{
#     "prompt": "Grazing sheep",
#     "size": "1024x1024",
#     "style": "vivid",
#     "quality": "hd"
#   }'
# main.py
from fastapi import FastAPI
from pydantic import BaseModel
import torch
from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline
from diffusers.utils import load_image
import base64
from io import BytesIO
import gc

app = FastAPI()

# --- é…ç½®å‚æ•°æ˜ å°„ ---
SIZE_MAP = {
    "1024x1024": (1024, 1024),
    "1024x1792": (1024, 1792),#æ˜¾å­˜ä¸å¤Ÿï¼Œé™ä½åˆ†è¾¨ç‡ 
    "1792x1024": (1792, 1024),
}

STYLE_MAP = {
    "vivid": "best quality, vibrant, dramatic lighting, saturated colors",
    "natural": "photorealistic, natural lighting, soft colors, realistic shadows"
}

QUALITY_MAP = {
    "standard": {"num_inference_steps": 30, "refiner": False},
    "hd": {"num_inference_steps": 40, "refiner": True}
}

# --- è®¾å¤‡è®¾ç½® ---
device = "cuda" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16

# --- æ‡’åŠ è½½æ¨¡å‹å‡½æ•° ---
def get_base_pipeline():
    pipe = StableDiffusionXLPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch_dtype,
        variant="fp16"
    )
    pipe.enable_attention_slicing()
    return pipe.to(device)

def get_refiner_pipeline():
    pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(
        "stabilityai/stable-diffusion-xl-refiner-1.0",
        torch_dtype=torch_dtype,
        variant="fp16"
    )
    pipe.enable_attention_slicing()
    return pipe.to(device)

# --- æ¸…ç† GPU æ˜¾å­˜ ---
def clear_gpu_memory():
    torch.cuda.empty_cache()
    gc.collect()

# --- API è¯·æ±‚æ ¼å¼ ---
class ImageRequest(BaseModel):
    prompt: str
    size: str = "1024x1024"
    style: str = "vivid"
    quality: str = "standard"

@app.post("/v1/images/generations")
async def generate_image(req: ImageRequest):
    width, height = SIZE_MAP.get(req.size, (1024, 1024))
    style_prompt = STYLE_MAP.get(req.style, "")
    quality_config = QUALITY_MAP.get(req.quality, {"num_inference_steps": 30, "refiner": False})

    full_prompt = f"{req.prompt}, {style_prompt}"
    negative_prompt = "blurry, low quality, distorted, ugly"

    # -------------------------------
    # ç¬¬ä¸€é˜¶æ®µï¼šBase æ¨¡å‹ç”Ÿæˆ
    # -------------------------------
    base_pipe = get_base_pipeline()

    try:
        # ğŸ” æ ¹æ®æ˜¯å¦éœ€è¦ refiner å†³å®šè¾“å‡ºç±»å‹
        output_type = "latent" if quality_config["refiner"] else "pil"

        result = base_pipe(
            prompt=full_prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=quality_config["num_inference_steps"],
            output_type=output_type,
        )

        if not quality_config["refiner"]:
            # âœ… ç›´æ¥è¿”å› PIL å›¾åƒ
            image = result.images[0]
        else:
            # âœ… è¿”å› latentï¼Œç”¨äº refiner
            image_latent = result.images[0]

    finally:
        base_pipe.to("cpu")
        del base_pipe
        clear_gpu_memory()

    # -------------------------------
    # ç¬¬äºŒé˜¶æ®µï¼šRefiner ç²¾ç‚¼ï¼ˆä»… high_qualityï¼‰
    # -------------------------------
    if quality_config["refiner"]:
        refiner_pipe = get_refiner_pipeline()

        try:
            image = refiner_pipe(
                prompt=full_prompt,
                negative_prompt=negative_prompt,
                image=image_latent,
                num_inference_steps=30,
                strength=0.3,
            ).images[0]

            # åˆ é™¤ latent
            del image_latent

        finally:
            refiner_pipe.to("cpu")
            del refiner_pipe
            clear_gpu_memory()

    # -------------------------------
    # è½¬ä¸º base64 è¿”å›
    # -------------------------------
    buffer = BytesIO()
    image.save(buffer, format="PNG")
    img_str = base64.b64encode(buffer.getvalue()).decode()

    return {
        "created": 1234567890,
        "data": [
            {
                "b64_json": img_str,
                "revised_prompt": full_prompt
            }
        ]
    }
